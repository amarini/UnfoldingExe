\documentclass[a4paper,11pt]{article}

\title{Solutions to unfolding distributions}
\author{ACM}
\date{\today}

\input{packages}
\input{acronyms}

\begin{document}
\maketitle

\section{Understanding unfolding}

The Unfolded spectra can be found using, eg, RooUnfold:
\begin{verbatim}
ROOT.gSystem.Load("${HOME}/Downloads/RooUnfold-1.1.1/libRooUnfold.so")
##  prepare the response matrix
# assume a flat prior
R = ROOT.RooUnfoldResponse(None,None,resp)
u = ROOT.RooUnfoldInvert(R,reco)
u.SetName("unfolder1")
h = u.Hreco(ROOT.RooUnfold.kNone) 
h.SetName("unfold")

## for meaningful errors
fluct=1.0
for j in range(0,reco.GetNbinsX() ):
	reco_fluct.SetBinError(j+1,fluct)

u2 = ROOT.RooUnfoldInvert(R,reco_fluct)
u2.SetName("unfolder2")
u2.SetNToys(1000)
h2 = u2.Hreco( ROOT.RooUnfold.kCovToy) ##  error propagation down with toys
h2.SetName("unfold2")

\end{verbatim}

The result is shown in figure~\ref{fig:sol1}: the unfolded distribution with no-fluctuations should be by-construction identical to the one used for generating it; 
small differences may be due to the numeric precision of the floating point representation inside a computer, that act as a fluctuation smearing. 
The one that had fluctuations inside, nevertheless is the \gls{ML} estimator and therefore the \gls{BLUE}, has a very huge variance.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.618\textwidth]{figs/gen-unfold.pdf}
	\caption{ \label{fig:sol1} The two unfolded distribution compared with the one used to generate them.}
\end{figure}

\FloatBarrier
\section{Regularization}
Regularization techniques are used to cure the high variance of the distribution, introducing an ad hoc bias. 

We start studying regularization to see the effect that it has on the distributions:
\begin{figure}[H]
	\centering
	\includegraphics[width=0.49\textwidth]{figs/unfold-bayes-reg.pdf}
	\includegraphics[width=0.49\textwidth]{figs/unfold-svd-reg.pdf}
	\caption{ \label{fig:sol:reg} The unfolded distribution for different regularization parameters. On the left, the iterative unfolding, on the right the Tickonov regularization. }
\end{figure}

For the iterative method based on Bayes' theorem the regularization is given by the number of iteration; the less iterations the closer the unfolded distribution to the prior we choose, usually obtained from \gls{MC}. The method will converge to the \gls{ML} solution with the increasing number of iterations.
For the \gls{SVD} implementation of the Tikonov regularization, the regularization is given by the number of singular values used in the inversion. The less singular values, the more the distribution is regularized. Using ``all'' the singular values we get close the \gls{ML} solution.

The regularization parameter is a \emph{choice} to make. 
There is no right and wrong value, but some wanted features are:
\begin{itemize}
	\item stability of the regularization with respect to the chosen regularization parameter.
	\item for the \gls{SVD}-method look at the $d_i$ distribution.
	\item error estimation after the unfolding should not be smaller than the one before it.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.49\textwidth]{figs/unfold-svd-ddistr.pdf}
	\includegraphics[width=0.49\textwidth]{figs/unfold-error-reg.pdf}
	\caption{ \label{fig:sol:reg2} Left: d-distribution for the \gls{SVD}-method. Right: ratio of the error before and after the unfolding.}
\end{figure}

\FloatBarrier
\section{Construct the response matrix}
\end{document}
